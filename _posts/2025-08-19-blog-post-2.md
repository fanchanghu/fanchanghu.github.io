---
title: '归一化流在变分推断中的应用'
date: 2025-08-19
permalink: /posts/2025/08/blog-post-2/
tags:
  - Normalizing Flows
  - 归一化流
  - 变分推断
  - Variational Inference
---

本文是关于 Rezende & Mohamed (2015) 的[Variational Inference with Normalizing Flows](https://arxiv.org/abs/1505.05770v6)学习总结。Normalizing Flow 的核心思想是通过一系列可逆变换（归一化流）将简单分布逐步塑造成复杂分布。在保持端到端可微的同时显著提升表达能力，更好的逼近真实的隐变量的后验分布。

## 问题背景

在深度生成模型（如 VAE、DLGM）中，我们需要用一个简单、可计算的分布 q(z|x) 去近似真实但难以求解的后验 p(z|x)。传统做法往往假设 q(z|x) 是单高斯或平均场，这就带来两个常见问题：
- **方差被低估**：单峰近似无法捕捉多模态，导致预测区间过窄、模型“自信过头”。
- **参数估计偏差**：后验（即单高斯或平均场）近似容量不足，使得 MAP 估计与真值存在系统性误差。
因此，急需一种**既灵活又高效**的方法来提升后验表达能力。

## 什么是归一化流（Normalizing Flows, NF）

归一化流是一类**通过可逆变换把简单分布变成复杂分布**的技术。
- 数学上，给定**初始密度** q₀(z₀)，经过 K 个可逆、可微的映射 f₁,…,f_K 后，得到

$$
z_K = f_K\circ\cdots\circ f_1(z_0),\quad
\log q_K(z_K)=\log q_0(z_0)-\sum_{k=1}^K \log|\det J_k|. \tag{1}
$$

- 每一步的 Jacobian 行列式可在 **O(D)** 时间计算（planar/radial flow）。
- 理论上，**无限步流**可逼近任意连续分布，从而突破传统平均场的限制。

平面流（planar flow）公式：

$$
\begin{align*}
f(z) &= z + uh(w^Tz + b), \tag{2} \\
\lambda &= \{ w \in R^D, u \in R^D, b \in R \}
\end{align*}
$$

径向流（radial flow）公式：

$$
\begin{align*}
f(z) &= z + βh(α, r)(z − z_0) , \tag{3} \\
r &= |z − z_0| , \\
h(α, r) &= 1/(α + r), \\
\lambda &= \{ z_0 \in R^D, α \in R^+, β \in R \}
\end{align*}
$$

## 为什么变分推断要使用归一化流

![Illustration Planar Flow Approximating 4 non-Gaussian 2D Distributions](/images/202508/normalizing-flow-1.png)
图1

- **高表达能力**：能刻画多峰、非高斯、非线性依赖的后验。图1展示了不同步长下归一化流的近似能力:a时真实后验；b是使用平面流近似的效果；c是作为比较基准的NICE方法的近似效果。
- **可扩展**：与 **amortized inference**（编码器一次性输出所有参数）结合，支持 mini-batch SGD 训练。
- **端到端可微**：reparameterization trick 使梯度可一次性反传，无需高方差的 score-function 估计。
- **渐进优势**：实验显示，随着流步数 K 增加，KL(q‖p) 单调下降，ELBO 单调上升，在 MNIST、CIFAR-10 上显著优于 NICE、HVI 等基线。

## 如何基于归一化流做变分推断

![Illustration Variational Inference with Normalizing Flows](/images/202508/normalizing-flow-2.png)
图2

基于归一化流的变分推断如图2所示，其步骤可归纳为“**编码 → 流动 → 解码 → 优化**”：
1. **编码器**：输入观测 x，输出
   - 初始潜变量参数 q₀ = N(μ, Σ)
   - K 步流的参数 λ_k
2. **流动**：从 q₀(z₀|x) 采样 z₀，经过 K 步可逆变换得到 z_K。
3. **解码器**：用 z_K 计算 \\( \log p_\theta(x|z_K) \\) ，而先验分布 p(z_K) 通常取标准高斯。
4. **优化**：Loss（基于平面流）为负ELBO：

$$
\begin{align*}
\mathcal L(\theta,\phi) &= D_{KL}[q_\phi(z|x) || p(z)] - E_{z \sim q_\phi}[\log p_\theta(x|z)] \\
&= E_{z_K \sim q_K}[\log q_K(z_K|x) - \log p(z_K) - \log p_\theta(x|z_K)] \\
&= E_{z_0 \sim q_0}[\log q_0(z_0|x) - \log p(z_K) - \log p_\theta(x|z_K) - \sum_{k=1}^{K}[\log |1+u_k^T\phi_k(z_{k-1})|]] \\
\end{align*}
$$

整个计算图可通过一次反向传播，给出编码器和解码器的梯度。

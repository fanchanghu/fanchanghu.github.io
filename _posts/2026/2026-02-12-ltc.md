---
title: 'Liquid Time-constant Networks 学习报告'
date: 2026-02-14
permalink: /posts/2026/02/ltc/
tags:
  - 液态时间常数网络
  - Liquid Time-constant Networks
  - LT-RNN
  - Nerual ODE
---

# Liquid Time-constant Networks (LTC) 学习报告

本报告是对 [Liquid Time-constant Networks](https://arxiv.org/abs/2006.04439) 的学习报告。LTC通过引入**输入依赖的液体时间常数**，使循环神经元的动态特性能够根据当前输入和状态自适应调整，从而在保持稳定性的同时提升表达能力和时序建模性能。

---

## 1. 引言与背景

连续时间循环神经网络（CT-RNN）和神经常微分方程（Neural ODE）为处理时间序列数据提供了强大的框架。传统CT-RNN通过引入一个固定的时间常数项来增强系统的稳定性，其形式为：

$$
\frac{d\mathbf{x}(t)}{dt} = -\frac{\mathbf{x}(t)}{\tau} + f(\mathbf{x}(t),\mathbf{I}(t),t,\theta)  \tag{1}
$$

> **CT-RNN的稳定性分析**：相比于直接定义导数的神经ODE（\\(\frac{d\mathbf{x}}{dt}=f(\cdot)\\)），CT-RNN增加了一项线性负反馈 \\(-\mathbf{x}/\tau\\)。这一项扮演着“阻尼”角色：无论神经网络 `f` 如何驱动状态，负反馈都会产生一个与当前状态相反的拉力，迫使系统趋向平衡点。这种机制有效防止了状态爆炸，使CT-RNN在长期演化中表现出更可控的动态特性，因此被称为“更稳定”的连续时间模型。该形式最早由Funahashi和Nakamura（1993）提出，是后续工作的基础。

然而，传统CT-RNN的时间常数 `τ` 是固定的，限制了模型对复杂动态的适应能力。LTC网络通过将 `τ` 变为由神经网络调节的可变量，迈出了关键一步。

---

## 2. LTC模型与液体时间常数

LTC的核心微分方程如下：

$$
\frac{d\mathbf{x}(t)}{dt} = -\left[ \frac{1}{\tau} + f(\mathbf{x}(t),\mathbf{I}(t),t,\theta) \right] \mathbf{x}(t) + f(\mathbf{x}(t),\mathbf{I}(t),t,\theta) A   \tag{2}
$$

其中 `f` 是一个非线性神经网络。对比CT-RNN，LTC的“有效时间常数”变为：

\\[
\tau_{\text{sys}} = \frac{1}{\frac{1}{\tau} + f(\cdot)}  \tag{3}
\\]

由于 `f` 随输入和状态变化，\\(\tau_{\text{sys}}\\) 也是动态的——作者称之为**液体时间常数**。

> **生物学启发**：该公式并非凭空创造，而是受到小型物种非脉冲神经元模型的启发。经典神经元电位方程 \\(\frac{dv}{dt} = -g_l v + S(t)\\) 中，突触总输入 `S(t)` 可近似为 \\(f(v,I)(A - v)\\)。代入后即得与LTC一致的数学结构。因此，LTC可视为生物神经元计算模型的抽象与扩展。

---

## 3. 数值求解：融合显式/隐式欧拉法

LTC方程属于刚性常微分方程，直接使用标准显式方法（如RK45）需要极小时同步长，而完全隐式方法又需迭代求解，计算昂贵。为此作者设计了一种**融合求解器（Fused Solver）**，其更新公式为：

$$
\mathbf{x}(t+\Delta t) = \frac{\mathbf{x}(t) + \Delta t \, f(\mathbf{x}(t),\mathbf{I}(t),t,\theta) A}{1 + \Delta t \left( \frac{1}{\tau} + f(\mathbf{x}(t),\mathbf{I}(t),t,\theta) \right)}  \tag{4}
$$

该公式的推导基于以下思想：在线性部分（公式2第一项中的 `x(t)`）采用隐式处理，将 `x(t)` 替换为未来值 `x(t + Δt)`，而非线性部分仍使用当前时刻值，从而使公式（2）对 `x(t + Δt)` 成为线性，可直接求解。

> **显式欧拉 vs 隐式欧拉**
> - **显式欧拉**：\\(x_{n+1} = x_n + \Delta t f(x_n, t_n)\\)，直接计算，但稳定性差，尤其对刚性系统需要极小步长。
> - **隐式欧拉**：\\(x_{n+1} = x_n + \Delta t f(x_{n+1}, t_{n+1})\\)，需解方程，稳定性极佳。隐式欧拉之所以稳定，是因为其形式强制数值解满足系统的内在耗散规律——即使步长很大，计算出的新状态也会被“拉向”平衡点，而非因外推而发散。
> **融合求解器**巧妙结合两者：获得隐式方法的稳定性，却无需迭代，因为通过部分线性化得到了封闭解。

---

## 4. 训练策略：Vanilla BPTT 与 伴随方法

论文选择使用标准的随时间反向传播（BPTT）来训练LTC，而非神经ODE常用的伴随灵敏度方法。

**BPTT vs 伴随方法**
- **BPTT**：将前向计算的所有中间结果存储下来，构建完整计算图，然后反向传播。优点是梯度精确，缺点是内存消耗与序列长度成正比。
- **伴随方法**：不存储中间状态，反向时重新解一次ODE来重构轨迹。内存恒定，但存在数值误差，因为重构的轨迹可能与前向不完全一致。

作者为了追求“高度精确的反向积分”，选择BPTT，以内存换精度，确保LTC能准确学习复杂动态。实际实现中，常采用截断BPTT（Truncated BPTT）来平衡内存和长程依赖。

---

## 5. 理论分析：稳定性与表达性

### 5.1 状态与时间常数的有界性（稳定性）

**定理1**：LTC神经元的有效时间常数 \\(\tau_{\text{sys}}\\) 有界：
$$
\frac{\tau}{1+\tau W_i} \le \tau_{\text{sys}} \le \tau  \tag{5}
$$
其中 \\(W_i\\) 为输入权重的某种上界。

**定理2**：神经元状态 \\(x_i(t)\\) 在有限时间区间内有界：
$$
\min(0, A_i^{\min}) \le x_i(t) \le \max(0, A_i^{\max})  \tag{6}
$$
这些定理保证即使输入无限增长，LTC的状态也不会爆炸，为表达性度量提供了稳定前提。

### 5.2 表达性度量：轨迹长度

![](/images/202602/ltc-1.png)
*图1 FNN 轨迹*

为了量化模型的表达能力，作者引入**轨迹长度**概念：在给定输入下，隐藏状态在潜在空间中运动路径的总长度，定义为
$$
L = \int_0^T \left\| \frac{d\mathbf{x}(t)}{dt} \right\| dt  \tag{7}
$$
轨迹越长，说明模型对输入的响应越丰富，能表示更复杂的动态模式。

> **轨迹长度的公平性考量**：如果模型本身不稳定（输出发散），即使是一条直线也能产生极长轨迹，但这并不能代表真正的表达力。因此，该度量必须在**状态有界**的前提下进行。LTC和对比模型（CT-RNN等）均已通过定理保证稳定性，因此较长的轨迹确实反映了更复杂的动态，而非单纯发散。

---

### 6. 实验验证

实验中，模型权重通过**随机初始化**确定，**未经训练**，旨在比较架构本身的**先天表达能力**。

为避免单次随机性的偏差，通常设定好均值与标准差，并对多个随机种子重复实验，确保结论的统计显著性。

为便于对比展示，输入统一为单位圆，输出使用主成分分析（PCA）映射回二维后的轨迹。

图1 展示了单位圆经过多层FNN后，每层的输出（100维）使用主成分分析（PCA）映射回二维后的轨迹。

![](/images/202602/ltc-2.png)
*图2 LTC 表达性对比*

上图比较了在相同设置下，LTC与LT-RNN和N-ODE产生的轨迹：
- A 网络在时间维度展开为3层，逐层比较，使用 Hard tanh 激活函数。
- B 网络参数使用不同分布初始化，单层比较，使用 Hard tanh 激活函数。
- C 不同宽度比较，使用 ReLU 激活函数。
- D 网络在时间维度展开为5层，逐层比较，使用 tanh 激活函数。
- E 不同宽度比较，使用 Hard tanh 激活函数。

从以上对比中可以观察到：

1. **LTC的轨迹更长更复杂**：相比LT-RNN和N-ODE，LTC 能够产生更长、更复杂的轨迹。

2. **激活函数的影响**：在轨迹长度实验中，使用Hard Tanh激活函数时，LTC的轨迹复杂度显著高于使用ReLU或Tanh（A、B、E 对比 C、D）。

---

## 7. 总结

LTC网络通过引入液体时间常数，将固定时间常数的CT-RNN扩展为更具表达力的动态系统。其核心贡献包括：
- 提出了一种生物启发的微分方程形式，并设计了高效稳定的融合求解器；
- 证明了模型的状态和时间常数均有界，保证了稳定性；
- 引入轨迹长度作为表达性度量，从理论和实验上验证了LTC的优越性；

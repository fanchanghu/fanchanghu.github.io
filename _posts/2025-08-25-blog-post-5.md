---
title: 'OaK 架构：一个基于经验的超级智能愿景'
date: 2025-08-25
permalink: /posts/2025/08/blog-post-5/
tags:
  - OaK
  - 超级智能
  - 经验
  - Agent
  - Rich Sutton
---

Richard Sutton 在 RLC 2025 和 AGI 2025 上发表的远程演讲《OaK 架构：一个基于经验的超级智能愿景》。演讲中，Sutton 介绍了他认为有望实现通用人工智能乃至超级智能的路径：
- 回顾了长期以来对简单且通用的 AI 智能体架构的追求
- 强调了从经验中学习、拟合世界的重要性
- 介绍了现有的常用智能体模型的架构及其缺陷
- OaK 架构

机器之心的整理：[【强化学习之父Richard Sutton】通向超级智能的八步愿景（最新演讲揭示OaK架构）](https://mp.weixin.qq.com/s/p9qj0SaOVptdVqiXAL8ezw?poc_token=HLDlpmijLCOShS_rCKZsDw59xBLluW_w6w9kuh2e)

---

主要内容大致可以分为两大部分：**对AGI实现方法的观点**和**对 OaK 架构的介绍**。

## 对AGI实现方法的观点

### 1. 我追寻的目标是一种简单且通用的 AI 智能体架构。

- 通用性：「不包含特定于任何世界的东西」「不包含任何领域知识」。
- 经验性：「随着运行时间经验而成长，而不是仅仅依赖某个专门的训练阶段」。
- 开放式抽象：「智能体能够不断发展自身的概念体系……复杂性不设上限，唯一的限制是计算资源」。

### 2. 智能体应该<font color=Red>只从</font>运行时经验中学习。

世界太复杂，只能近似。

心智的实际内容，属于任意的、固有复杂的外部世界的一部分。

智能体所学到的任何知识都不可能是「完全正确」的，它也不可能实现真正的「最优」行为。

我们应当预设的，只是那些可以主动**发现并捕捉复杂性的元方法（meta-methods）**。我们所追求的是像人类一样具有发现能力的 AI 智能体，而不是那些仅仅包含我们已经发现的知识的系统。

为了实现「通用性」，我们需要**刻意弱化领域知识的作用**。

如果我们的目标是理解智能，那么理想的智能体架构就**不应该在设计时对任何特定世界做出预设承诺**。

### 3. Reward is Enough

在一个足够复杂的世界中，**一个简单的奖励就足以引导出智能的全部表现**。

AI 研究的目标是设计出一个有效的智能体，它能够在现实世界中完成目标。强化学习 ... 用一个标量信号奖励来表示智能体的目标。 ... 我认为，这一设定丝毫不是一种限制，相反，它是一种非常清晰、优雅的定义目标的方式。

推荐了论文：[Settling the Reward Hypothesis](https://arxiv.org/abs/2212.10420)

## 对 OaK 架构的介绍

### 一般的Agent模型

首先介绍了一般的Agent模型（如下图）：

![Illustration Common Agent Model](/images/202508/oak-1.png)
图1

从外部视角来看，智能体的核心就是由三个「红色部分」组成的**经验接口（experiential interface）**：你会接收到**奖励信号（reward）**，你可以采取**行动（action）**，你会接收到来自环境的某种**观察信号（observations）**。

从内部视角来看，智能体则包括以下四个组成部分：**感知**、**价值函数**、**反应策略**、**转移模型**。图中蓝色部分，表示这些组件之间是如何互相连接的。这些连接也就是所谓的**状态特征向量（state feature vector）**。这是用来表示世界状态的方式。
- **感知（perception）**：基于输入信号和过去的动作来构建对当前状况的认知。
- **反应策略（reactive policy）**：输入状态表示，然后得到行动的动作。
- **价值函数（value function）**：价值函数可以提供这样的信息：「我现在的表现很好」或「我现在表现很差」，也就是说，它用来判断事情是变好了还是变糟了。价值函数使得 Agent 能够学习和改进。
- **转移模型（transition model）**：在给定当前状态的情况下，根据一个特定的动作，预测可能到达的下一个状态。它是我们用来进行规划的关键结构。

### 通用架构的问题

核心缺失在于：这个模型虽然完整，但它仍然停留在低层次的表示上。动作是瞬时的，奖励是瞬时的，观察也是瞬时的。而我们所追求的智能行为，必须涉及到更高层次的抽象。

我们需要发展出概念（concepts），发展出一整套高级思维方式（ways of thinking）。

因此，在这个常用模型基础上，我认为最需要补充的就是**开放式抽象（open-ended abstractions）**，这正是 OaK 架构试图引入的新要素。

> 我的理解是，在一般Agent框架中，如果Agent要去北京，那么具体的“动作-状态”序列可能是：「向前走一步，到达A点；向前走一步，到达B点； ...；向前走一步，到达车站收票窗口；询问去北京的车次，得到回答；确定购买， ...」。这种动作和状态对这个任务来说**过于细节**了，因此，我们需要Agent能够将这个任务总结为类似：「走到火车站；购买车票；乘车到北京；下车走到目的地」这种更高层次的抽象。

### OaK

![Illustration OaK Architecture](/images/202508/oak-2.png)
图2

OaK 架构的关键扩展，是引入了一系列辅助子问题，这些子问题是相对于主问题（获得奖励）而言的「次级任务」。

主任务仍然是：最大化奖励。而这些子任务，我们即将反复看到一个术语：「**与奖励一致的特征达成子问题（reward-respecting subproblems of feature attainment）**」。

整个架构与之前几乎相同。但有一个关键变化：在原有的策略之后新增了一组被称为「**选项（options）**」的结构，它们可以理解为更高层次的策略；而在原有的价值函数之后也增加了多个新的价值函数。

每一个子问题都是一个独立的问题，因此必须为每个子问题配备一个独立的价值函数，以衡量当前在该子问题上的表现好坏。因此，系统中需要更多的价值函数来支持多个子任务的评估。

因此，现在该架构有四类组件：虽然感知和状态特征向量的机制保持不变，但策略和价值函数这两个部分现在都变成了多个。

我们仍然保留之前的感知模块，负责生成状态特征向量，这个向量会被所有子任务共享。

现在每个子任务都拥有自己的一组选项策略，用于制定适合该任务的行为方式；而对应的，每个子任务也拥有一个独立的价值函数，用于评估当前行为在该子任务上的效果。

我们的所有知识，其实都体现在状态转移模型之中。也就是说，它代表了我们对世界的理解：当我们采取某种行动时，世界将如何变化。特别是当我们采取那些更高层级的复杂行为 —— 也就是所谓的「选项（options）」时，世界状态可能发生的变化。

「OaK」这一架构名称，正是来源于这两个关键词：**Options（选项）** 和 **Knowledge（知识）**。

> 还是以之前的“乘车去北京”为例，「走到火车站」；「购买车票」；「乘车到北京」这些就是**与奖励一致的特征达成子问题**。
> 这些子问题的解（即策略和终止条件）就是**Options（选项）**。比如：「走到火车站」这个子问题的 Option 是「向前走一步，到达A点；向前走一步，到达B点； ...；向前走一步，到达车站收票窗口；」。其中，「到达车站收票窗口」即为终止条件。
> 用不同 Option 和它们的终止条件（终止状态）组成的“Option-State”序列来解决更高层次的问题的方法，就是**Knowledge（知识）**。比如「走到火车站；购买车票；乘车到北京；下车走到目的地」这四个 Option 序列就是关于“乘车去北京”问题的知识。
> 从这个角度看，Option = 高层次的Action；终止条件 = 高层次的状态；知识 = 高层次的转移模型。

### OaK 的八个步骤

1. 学习用于最大化奖励的策略和价值函数；
2. 生成新的状态特征；
3. 对这些特征进行排序，确定其重要性；
4. 基于排名靠前的特征，构建对应的子问题；
5. 为每个子问题学习解法；
6. 为每个子问题的解法学习对应的状态转移模型；
7. 执行规划；
8. 维护关于整个系统中各项元素效用的元数据。

并分析了每个步骤当前的最新研究进展（如下图）：<font color=Blue>蓝色</font>表示如果能实现持续深度学习与元学习，这部分就可以完成；<font color=Red>红色</font>表示有很多想法，但没有具体方案；<font color=Orange>黄色</font>表示看起来很容易，但必须等其他部分完成之后才能进行；<font color=Green>绿色</font>表示似乎已经能够做到。

![Illustration OaK Architecture](/images/202508/oak-3.png)
图3
